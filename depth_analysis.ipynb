{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ff92cf",
   "metadata": {},
   "source": [
    "# Initialize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc8b5f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2662668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "from model import VAE_priorCategorical, VAE_priorHFM\n",
    "import metadata as md\n",
    "from datasets import Dataset_HFM, Dataset_pureHFM, load_dsprites\n",
    "from utilities import sample_images, get_empirical_latent_distribution, calculate_kl_divergence_with_HFM\n",
    "from peak_analysis import get_peaks_data, accumulate_peaks_data, plot_peaks_data, find_peaks_from_empirical_distribution\n",
    "from find_gauge import calculate_HFM_over_disordered_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "948ba460",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335248a3",
   "metadata": {},
   "source": [
    "# Datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b97214e",
   "metadata": {},
   "source": [
    "## dSprites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803e2ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_dSprites, val_loader_dSprites = load_dsprites()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe983ce",
   "metadata": {},
   "source": [
    "## MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77b977a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_MNIST = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        '/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor()\n",
    "        ),\n",
    "    batch_size=md.batch_size,\n",
    "    shuffle=True\n",
    "    )\n",
    "\n",
    "val_loader_MNIST = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        '/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor()\n",
    "        ),\n",
    "    batch_size=md.batch_size,\n",
    "    shuffle=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8f4a4f",
   "metadata": {},
   "source": [
    "## FashionMNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad907d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_FashionMNIST = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST(\n",
    "        '/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor()\n",
    "        ),\n",
    "    batch_size=md.batch_size,\n",
    "    shuffle=True\n",
    "    )\n",
    "\n",
    "val_loader_FashionMNIST = torch.utils.data.DataLoader(\n",
    "    datasets.FashionMNIST(\n",
    "        '/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor()\n",
    "        ),\n",
    "    batch_size=md.batch_size,\n",
    "    shuffle=False\n",
    "    )\n",
    "## pureHFM\n",
    "dataset_HFM_train = Dataset_pureHFM(csv_file='/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data/pureHFM/512features/glog2_train60000.pt',\n",
    "                        root_dir='/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data/pureHFM')\n",
    "\n",
    "train_loader_pureHFM = DataLoader(\n",
    "    dataset_HFM_train,\n",
    "    batch_size=md.batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataset_HFM_val = Dataset_pureHFM(csv_file='/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data/pureHFM/512features/glog2_validation10000.pt',\n",
    "                            root_dir='/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data/pureHFM')\n",
    "\n",
    "val_loader_pureHFM = DataLoader(\n",
    "    dataset_HFM_val, # Importante: usa dataset_HFM_val qui, non dataset_HFM\n",
    "    batch_size=md.batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "## expandedHFM 32-1024\n",
    "dataset_HFM_train = Dataset_HFM(csv_file='/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data/expandedHFM/32_1024features/2hl_glog2_train60000.pt',\n",
    "                        root_dir='/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data/pureHFM')\n",
    "\n",
    "train_loader_expandedHFM_32_1024 = DataLoader(\n",
    "    dataset_HFM_train,\n",
    "    batch_size=md.batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataset_HFM_val = Dataset_HFM(csv_file='/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data/expandedHFM/32_1024features/2hl_glog2_validation10000.pt',\n",
    "                            root_dir='/Users/enricofrausin/Programmazione/PythonProjects/Fisica/data/pureHFM')\n",
    "\n",
    "val_loader_expandedHFM_32_1024 = DataLoader(\n",
    "    dataset_HFM_val, # Importante: usa dataset_HFM_val qui, non dataset_HFM\n",
    "    batch_size=md.batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "# PriorHFM, klG = log2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405a2779",
   "metadata": {},
   "source": [
    "# PriorHFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cc3fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from find_gauge import flip_gauge_bits, get_feature_frequencies_sorted, reorder_bit_states_by_frequency, return_goodgauged_empirical_probs, find_optimal_g_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d8b8ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_dict = {(1,1,0,1,0,0): 0.1,\n",
    "              (0,1,0,1,0,1): 0.3,\n",
    "              (1,0,0,1,1,1): 0.2,\n",
    "              (1,0,1,1,0,1): 0.2,\n",
    "              (1,0,1,1,1,1): 0.2}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d977d4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e370d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 0, 0, 0, 1, 0): 0.1,\n",
       " (0, 0, 0, 0, 0, 0): 0.3,\n",
       " (1, 1, 0, 1, 0, 0): 0.2,\n",
       " (1, 1, 1, 0, 0, 0): 0.2,\n",
       " (1, 1, 1, 1, 0, 0): 0.2}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_goodgauged_empirical_probs(debug_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7260413b",
   "metadata": {},
   "source": [
    "## train over MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff65e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = train_loader_MNIST\n",
    "val_loader = val_loader_MNIST\n",
    "input_dim = 784\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b83b152",
   "metadata": {},
   "source": [
    "### latent_dim = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c74d8ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "iteration over a 0-d tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m my_model = VAE_priorCategorical(input_dim=input_dim, categorical_dim=\u001b[32m2\u001b[39m, latent_dim=\u001b[32m8\u001b[39m, decrease_rate=\u001b[32m0.5\u001b[39m, device=device, num_hidden_layers=\u001b[32m1\u001b[39m, LayerNorm=\u001b[38;5;28;01mTrue\u001b[39;00m).to(device)\n\u001b[32m      4\u001b[39m my_model.load_state_dict(torch.load(\u001b[33m'\u001b[39m\u001b[33m/Users/enricofrausin/Programmazione/PythonProjects/Fisica/Architetture/VAE/discrete/models_parameters/priorCategorical/MNIST/ld8_glog2_ep15_lmb01_dr05_gKLlog2_LN_1hl_0.pth\u001b[39m\u001b[33m'\u001b[39m, map_location=device))\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcalculate_HFM_over_disordered_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programmazione/PythonProjects/Fisica/Architetture/VAE/discrete/find_gauge.py:148\u001b[39m, in \u001b[36mcalculate_HFM_over_disordered_states\u001b[39m\u001b[34m(model, dataloader, device, return_goodgauged_probs, return_empirical_entropy)\u001b[39m\n\u001b[32m    145\u001b[39m gauge_probs = return_goodgauged_empirical_probs(empirical_probs)\n\u001b[32m    146\u001b[39m optimal_g, min_expected_ms = find_optimal_g_parameter(gauge_probs)\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m kl_divergence, empirical_entropy = calculate_kl_divergence_with_HFM(gauge_probs, optimal_g, normalize_theoricalHFM=\u001b[38;5;28;01mFalse\u001b[39;00m, return_emp_distr_entropy=return_empirical_entropy)\n\u001b[32m    151\u001b[39m gauge_probs = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_goodgauged_probs \u001b[38;5;28;01melse\u001b[39;00m gauge_probs\n\u001b[32m    152\u001b[39m empirical_entropy = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_empirical_entropy \u001b[38;5;28;01melse\u001b[39;00m empirical_entropy\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Programmazione/Python_nn/.venv/lib/python3.11/site-packages/torch/_tensor.py:1185\u001b[39m, in \u001b[36mTensor.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1175\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1176\u001b[39m     \u001b[38;5;66;03m# NB: we use 'imap' and not 'map' here, so that in Python 2 we get a\u001b[39;00m\n\u001b[32m   1177\u001b[39m     \u001b[38;5;66;03m# generator and don't eagerly perform all the indexes.  This could\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1182\u001b[39m     \u001b[38;5;66;03m# NB: We have intentionally skipped __torch_function__ dispatch here.\u001b[39;00m\n\u001b[32m   1183\u001b[39m     \u001b[38;5;66;03m# See gh-54457\u001b[39;00m\n\u001b[32m   1184\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dim() == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1185\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33miteration over a 0-d tensor\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._C._get_tracing_state():\n\u001b[32m   1187\u001b[39m         warnings.warn(\n\u001b[32m   1188\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mIterating over a tensor might cause the trace to be incorrect. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1189\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mPassing a tensor of different shape won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt change the number of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1193\u001b[39m             stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m   1194\u001b[39m         )\n",
      "\u001b[31mTypeError\u001b[39m: iteration over a 0-d tensor"
     ]
    }
   ],
   "source": [
    "\n",
    "# hidden layer = 1\n",
    "my_model = VAE_priorCategorical(input_dim=input_dim, categorical_dim=2, latent_dim=8, decrease_rate=0.5, device=device, num_hidden_layers=1, LayerNorm=True).to(device)\n",
    "my_model.load_state_dict(torch.load('/Users/enricofrausin/Programmazione/PythonProjects/Fisica/Architetture/VAE/discrete/models_parameters/priorCategorical/MNIST/ld8_glog2_ep15_lmb01_dr05_gKLlog2_LN_1hl_0.pth', map_location=device))\n",
    "print(calculate_HFM_over_disordered_states(my_model, train_loader, device=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e28d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# hidden layer = 2\n",
    "my_model = VAE_priorHFM(input_dim=input_dim, latent_dim=8, g=np.log(2), decrease_rate=0.5, device=device, num_hidden_layers=2, LayerNorm=True).to(device)\n",
    "my_model.load_state_dict(torch.load('/Users/enricofrausin/Programmazione/PythonProjects/Fisica/Architetture/VAE/discrete/models_parameters/priorHFM/MNIST/ld8_glog2_ep15_lmb01_dr05_gKLlog2_NL_2hl_0.pth', map_location=device))\n",
    "current_data_dict = get_peaks_data(my_model, train_loader, device, kl_args={'g': different_klG})\n",
    "accumulate_peaks_data(data_dict_ld8_klg, current_data_dict)\n",
    "\n",
    "# hidden layer = 3\n",
    "my_model = VAE_priorHFM(input_dim=input_dim, latent_dim=8, g=np.log(2), decrease_rate=0.5, device=device, num_hidden_layers=3, LayerNorm=True).to(device)\n",
    "my_model.load_state_dict(torch.load('/Users/enricofrausin/Programmazione/PythonProjects/Fisica/Architetture/VAE/discrete/models_parameters/priorHFM/MNIST/ld8_glog2_ep15_lmb01_dr05_gKLlog2_NL_3hl_0.pth', map_location=device))\n",
    "current_data_dict = get_peaks_data(my_model, train_loader, device, kl_args={'g': different_klG})\n",
    "accumulate_peaks_data(data_dict_ld8_klg, current_data_dict)\n",
    "\n",
    "# hidden layer = 4\n",
    "my_model = VAE_priorHFM(input_dim=input_dim, latent_dim=8, g=np.log(2), decrease_rate=0.5, device=device, num_hidden_layers=4, LayerNorm=True).to(device)\n",
    "my_model.load_state_dict(torch.load('/Users/enricofrausin/Programmazione/PythonProjects/Fisica/Architetture/VAE/discrete/models_parameters/priorHFM/MNIST/ld8_glog2_ep15_lmb01_dr05_gKLlog2_LN_4hl_0.pth', map_location=device))\n",
    "current_data_dict = get_peaks_data(my_model, train_loader, device, kl_args={'g': different_klG})\n",
    "accumulate_peaks_data(data_dict_ld8_klg, current_data_dict)\n",
    "\n",
    "# hidden layer = 5\n",
    "my_model = VAE_priorHFM(input_dim=input_dim, latent_dim=8, g=np.log(2), decrease_rate=0.55, device=device, num_hidden_layers=5, LayerNorm=True).to(device)\n",
    "my_model.load_state_dict(torch.load('/Users/enricofrausin/Programmazione/PythonProjects/Fisica/Architetture/VAE/discrete/models_parameters/priorHFM/MNIST/ld8_glog2_ep15_lmb01_dr055_gKLlog2_NL_5hl_0.pth', map_location=device))\n",
    "current_data_dict = get_peaks_data(my_model, train_loader, device, kl_args={'g': different_klG})\n",
    "accumulate_peaks_data(data_dict_ld8_klg, current_data_dict)\n",
    "\n",
    "# hidden layer = 6\n",
    "my_model = VAE_priorHFM(input_dim=input_dim, latent_dim=8, g=np.log(2), decrease_rate=0.6, device=device, num_hidden_layers=6, LayerNorm=True).to(device)\n",
    "my_model.load_state_dict(torch.load('/Users/enricofrausin/Programmazione/PythonProjects/Fisica/Architetture/VAE/discrete/models_parameters/priorHFM/MNIST/ld8_glog2_ep15_lmb01_dr06_gKLlog2_NL_6hl_0.pth', map_location=device))\n",
    "current_data_dict = get_peaks_data(my_model, train_loader, device, kl_args={'g': different_klG})\n",
    "accumulate_peaks_data(data_dict_ld8_klg, current_data_dict)\n",
    "\n",
    "print(data_dict_ld8_klg['peaks_number'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Python_nn)",
   "language": "python",
   "name": "python_nn_3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ae25902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Categorical\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "947c43a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizzo Apple Silicon GPU (MPS)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "batch_size = 128\n",
    "temperature = 1.0\n",
    "seed = 0\n",
    "log_interval = 100\n",
    "log_interval_writer = 100\n",
    "hard = False\n",
    "latent_dim = 20\n",
    "categorical_dim = 2\n",
    "temp_min = 0.5\n",
    "ANNEAL_RATE = 0.00003\n",
    "\n",
    "g = 0.7\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Utilizzo Apple Silicon GPU (MPS)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Utilizzo NVIDIA GPU (CUDA)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Utilizzo la CPU\")\n",
    "\n",
    "# is_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(seed)\n",
    "if device.type == \"cuda\": # Mantieni la seed per CUDA se presente\n",
    "    torch.cuda.manual_seed(seed)\n",
    "elif device.type == \"mps\": # Imposta la seed anche per MPS se vuoi riproducibilità\n",
    "    torch.mps.manual_seed(seed)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device.type == \"cuda\" or device.type == \"mps\" else {} # pin_memory può essere utile anche per MPS\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        './data/MNIST',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor()\n",
    "        ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    **kwargs\n",
    "    )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        './data/MNIST',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor()\n",
    "        ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    **kwargs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629a76ae",
   "metadata": {},
   "source": [
    "## Gumbel softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf79c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_gumbel(shape, eps=1e-20):\n",
    "    # sample from a uniform distribution\n",
    "    U = torch.rand(shape)\n",
    "    return -torch.log(-torch.log(U.to(device) + eps) + eps)\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature):\n",
    "    y = logits + sample_gumbel(logits.size())\n",
    "    return F.softmax(y / temperature, dim=-1)\n",
    "\n",
    "\n",
    "def gumbel_softmax(logits, temperature, hard=False):\n",
    "    y = gumbel_softmax_sample(logits, temperature)\n",
    "    \n",
    "    if not hard:\n",
    "        return y.view(-1, latent_dim * categorical_dim)\n",
    "    \n",
    "    shape = y.size()\n",
    "    _, ind = y.max(dim=-1)\n",
    "    y_hard = torch.zeros_like(y).view(-1, shape[-1])\n",
    "    y_hard.scatter_(1, ind.view(-1, 1), 1)\n",
    "    y_hard = y_hard.view(*shape)\n",
    "    # skip the gradient of y_hard\n",
    "    y_hard = (y_hard - y).detach() + y \n",
    "    return y_hard.view(-1, latent_dim * categorical_dim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17316138",
   "metadata": {},
   "source": [
    "## alternative gumbel softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762f08ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gumbel_softmax(logits, tau, hard=False):\n",
    "    U = torch.rand_like(logits)\n",
    "    G = -torch.log(-torch.log(U + 1e-20) + 1e-20)\n",
    "    y = F.softmax((logits + G) / tau, dim=-1)\n",
    "\n",
    "    if hard:\n",
    "        y_hard = torch.zeros_like(y)\n",
    "        y_hard.scatter_(-1, y.argmax(dim=-1, keepdim=True), 1.0)\n",
    "        y = (y_hard - y).detach() + y  # straight-through estimator\n",
    "\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c220620",
   "metadata": {},
   "source": [
    "# HFM distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "629a3a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_s_i(n, k, g): #0-indexed k\n",
    "    '''\n",
    "    n = total number of features\n",
    "    k = k_th - 1 feature, 0-idexed\n",
    "    g = constant in HFM distribution\n",
    "    '''\n",
    "    xi = 2 * np.exp(-g)\n",
    "    if abs(xi - 1) < 1e-6: #handles the case xi =1\n",
    "        E = (n - (k+1) + 2) / (2 * (n+1))\n",
    "    else:\n",
    "        E = 0.5 * (1 + (xi**(k) - 1) * (xi - 2) / (xi**n + xi -2))\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f3f567",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.01,19)\n",
    "plt.plot(x,mean_s_i(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f19ee0",
   "metadata": {},
   "source": [
    "# Class VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51b88c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_model(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(VAE_model, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, latent_dim * categorical_dim)\n",
    "        self.fc4 = nn.Linear(latent_dim * categorical_dim, 256)\n",
    "        self.fc5 = nn.Linear(256, 512)\n",
    "        self.fc6 = nn.Linear(512, 784)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def sample_img(self, img, temp, random=True):\n",
    "        with torch.no_grad():\n",
    "            logits_z = self.encode(img.view(-1, 784))\n",
    "            logits_z = logits_z.view(-1, latent_dim, categorical_dim)\n",
    "            if random:\n",
    "                latent_z = gumbel_softmax(logits_z, temp, True)\n",
    "            else:\n",
    "                latent_z = logits_z.view(-1, latent_dim * categorical_dim)\n",
    "            logits_x = self.decode(latent_z)\n",
    "            dist_x = torch.distributions.Bernoulli(probs=logits_x)\n",
    "            sampled_img = dist_x.sample()\n",
    "        return sampled_img\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = self.relu(self.fc1(x))\n",
    "        h2 = self.relu(self.fc2(h1))\n",
    "        return self.relu(self.fc3(h2))\n",
    "\n",
    "    def decode(self, z):\n",
    "        h4 = self.relu(self.fc4(z))\n",
    "        h5 = self.relu(self.fc5(h4))\n",
    "        return self.sigmoid(self.fc6(h5))\n",
    "\n",
    "    def forward(self, data, temp, hard):\n",
    "        logits_z = self.encode(data.view(-1, 784))\n",
    "        logits_z = logits_z.view(-1, latent_dim, categorical_dim)\n",
    "\n",
    "        probs_z = F.softmax(logits_z, dim=-1)\n",
    "        posterior_distrib = torch.distributions.Categorical(probs=probs_z)\n",
    "\n",
    "        prior_probs_list = []\n",
    "        for i in range(latent_dim):\n",
    "            prob_activation = mean_s_i(latent_dim,i,g)\n",
    "            prob_nonactivation = 1 - prob_activation\n",
    "            prior_probs_list.append([prob_activation, prob_nonactivation])\n",
    "\n",
    "        probs_prior_base = torch.tensor(prior_probs_list, device=device, dtype=torch.float32)\n",
    "        probs_prior = probs_prior_base.unsqueeze(0).expand(data.size(0), -1, -1)\n",
    "        prior_distrib = torch.distributions.Categorical(probs=probs_prior)\n",
    "\n",
    "\n",
    "        latent_z = gumbel_softmax(logits_z, temp)\n",
    "        latent_z = latent_z.view(-1, latent_dim * categorical_dim)\n",
    "\n",
    "        probs_x = self.decode(latent_z)\n",
    "        dist_x = torch.distributions.Bernoulli(probs=probs_x, validate_args=False)\n",
    "\n",
    "        rec_loss = dist_x.log_prob(data.view(-1, 784)).sum(dim=-1)\n",
    "        logits_z_log = F.log_softmax(logits_z, dim=-1)\n",
    "\n",
    "        #KL è la somma su tutte le (singole KL calcolate sulla distr di prob di bernoulli di ogni feature), non ancora sommata su ogni esempio del batch \n",
    "        KL = (posterior_distrib.probs * (logits_z_log - prior_distrib.probs.log())).view(-1, latent_dim * categorical_dim).mean(dim=-1)\n",
    "        elbo = rec_loss - KL\n",
    "        # a questo punto si fa la media su tutti i valori del batch\n",
    "        loss = -elbo.mean()\n",
    "        return loss, KL.mean(), rec_loss.mean()\n",
    "    \n",
    "    def sample_from_prior(self, num_samples=1, temp_eval=0.01):\n",
    "        \"\"\"\n",
    "        Genera immagini campionando dallo spazio latente (prior).\n",
    "        num_samples: Quante immagini vuoi generare.\n",
    "        temp_eval: La temperatura da usare per la Gumbel-Softmax.\n",
    "                Un valore molto basso (~0.01) simula un campionamento one-hot.\n",
    "                Un valore di 1.0 rende il campionamento più \"soft\".\n",
    "        \"\"\"\n",
    "        self.eval() # Imposta il modello in modalità valutazione\n",
    "        with torch.no_grad(): # Non abbiamo bisogno di calcolare i gradienti qui\n",
    "\n",
    "            prior_probs_list = []\n",
    "            for i in range(latent_dim):\n",
    "                prob_cat0 = mean_s_i(i)\n",
    "                prob_cat1 = 1.0 - prob_cat0\n",
    "                prior_probs_list.append([prob_cat0, prob_cat1])\n",
    "\n",
    "            probs_prior_base = torch.tensor(prior_probs_list, device=device, dtype=torch.float32)\n",
    "\n",
    "            sampled_indices = torch.distributions.Categorical(probs=probs_prior_base).sample((num_samples,)).to(device)\n",
    "            # sampled_indices avrà forma (num_samples, latent_dim)\n",
    "\n",
    "            # Converti gli indici campionati in un formato one-hot (o soft)\n",
    "            # Per fare un sampling \"hard\" (one-hot), possiamo usare scatter_\n",
    "            # o direttamente creare i one-hot da sampled_indices\n",
    "            latent_z_one_hot = torch.zeros(num_samples, latent_dim, categorical_dim, device=device)\n",
    "            latent_z_one_hot.scatter_(-1, sampled_indices.unsqueeze(-1), 1)\n",
    "\n",
    "            latent_z_sampled = latent_z_one_hot.view(num_samples, latent_dim * categorical_dim)\n",
    "\n",
    "\n",
    "            probs_x = self.decode(latent_z_sampled)\n",
    "\n",
    "            dist_x = torch.distributions.Bernoulli(probs=probs_x)\n",
    "            generated_img = dist_x.sample()\n",
    "\n",
    "        self.train() # Riporta il modello in modalità addestramento\n",
    "        return generated_img # Ritorna le immagini generate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a67104",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8e35ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir='runs/discrete_VAE/_20hid_with_mean_KL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb9549b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, epochs):\n",
    "    global_batch_idx = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        temp = temperature\n",
    "\n",
    "        for batch_idx, (data, _) in enumerate(train_loader):\n",
    "            global_batch_idx += 1\n",
    "            # Sposta i dati sul device corretto\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss, KL, rec_loss = model(data, temp, hard)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item() * len(data)\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % 100 == 1:\n",
    "                temp = np.maximum(temp * np.exp(-ANNEAL_RATE * batch_idx), temp_min)\n",
    "\n",
    "            '''\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader),\n",
    "                        loss.item()))\n",
    "                print(\"Temperature : \", temp)\n",
    "            '''\n",
    "\n",
    "            if global_batch_idx % log_interval_writer == 0:\n",
    "                writer.add_scalar('KL/Train', KL, global_step=global_batch_idx)\n",
    "                writer.add_scalar('rec_loss/Train', rec_loss, global_step=global_batch_idx)\n",
    "\n",
    "\n",
    "        writer.add_scalar('Loss/Train', train_loss/len(train_loader.dataset), global_step=epoch)\n",
    "\n",
    "\n",
    "\n",
    "        '''\n",
    "        # Sposta l'immagine campionata sulla CPU per la visualizzazione con matplotlib\n",
    "        sampled = model.sample_img(data[0].view(-1, 28*28), temp).view(28, 28).detach().cpu()\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(6,4))\n",
    "        fig.suptitle('Reconstructed vs Real')\n",
    "        axs[0].imshow(sampled.reshape(28,28))\n",
    "        axs[0].axis('off')\n",
    "        axs[1].imshow(data[0].reshape(28,28).detach().cpu())\n",
    "        axs[1].axis('off')\n",
    "        plt.show()\n",
    "        '''\n",
    "\n",
    "        print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "            epoch, train_loss / len(train_loader.dataset)))\n",
    "        \n",
    "        # Validation\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss_sum = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, _) in enumerate(val_loader):\n",
    "                data = data.to(device)\n",
    "                loss, KL, rec_loss = model(data, temp, hard=True)\n",
    "                val_loss_sum += loss.item() * len(data)\n",
    "\n",
    "        writer.add_scalar('Loss/Validation', val_loss_sum/len(val_loader.dataset), global_step=epoch)\n",
    "\n",
    "        # Log histogram of weights and gradients\n",
    "        for name, param in model.named_parameters():\n",
    "            writer.add_histogram(f'Weights/{name}', param, global_step=epoch)\n",
    "            if param.grad is not None:\n",
    "                writer.add_histogram(f'Grads/{name}', param.grad, global_step=epoch)\n",
    "\n",
    "    writer.close()\n",
    "    print(\"Training completato e dati scritti su tensorboard\")\n",
    "\n",
    "\n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9963bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/enricofrausin/Programmazione/Python_nn/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 Average loss: 200.2588\n",
      "====> Epoch: 1 Average loss: 166.9122\n",
      "====> Epoch: 2 Average loss: 144.9959\n",
      "====> Epoch: 3 Average loss: 135.7206\n",
      "====> Epoch: 4 Average loss: 131.5733\n",
      "====> Epoch: 5 Average loss: 128.6622\n",
      "====> Epoch: 6 Average loss: 126.2670\n",
      "====> Epoch: 7 Average loss: 123.8236\n",
      "====> Epoch: 8 Average loss: 121.6113\n",
      "====> Epoch: 9 Average loss: 119.9646\n",
      "====> Epoch: 10 Average loss: 118.5110\n",
      "====> Epoch: 11 Average loss: 117.1469\n",
      "====> Epoch: 12 Average loss: 115.8264\n",
      "====> Epoch: 13 Average loss: 114.7393\n",
      "====> Epoch: 14 Average loss: 113.7097\n",
      "Training completato e dati scritti su tensorboard\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "my_model = VAE_model()\n",
    "my_model.to(device)\n",
    "optimizer = optim.Adam(my_model.parameters(), lr=1e-3)\n",
    "\n",
    "train(my_model, optimizer, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4687879",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bfefa73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_generated_images = 5\n",
    "generated_images = my_model.sample_from_prior(num_samples=num_generated_images)\n",
    "\n",
    "# Visualizza le immagini generate\n",
    "plt.figure(figsize=(num_generated_images * 2, 2))\n",
    "plt.suptitle(\"Immagini generate dal prior\", fontsize=16)\n",
    "for i in range(num_generated_images):\n",
    "    plt.subplot(1, num_generated_images, i + 1)\n",
    "    plt.imshow(generated_images[i].view(28, 28).detach().cpu().numpy(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f791d01a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Python_nn)",
   "language": "python",
   "name": "python_nn_3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

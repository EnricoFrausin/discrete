{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ae25902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Categorical\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "947c43a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizzo Apple Silicon GPU (MPS)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "batch_size = 128\n",
    "temperature = 1.0\n",
    "seed = 0\n",
    "log_interval = 600\n",
    "log_interval_writer = 100\n",
    "hard = False\n",
    "latent_dim = 15\n",
    "categorical_dim = 2\n",
    "temp_min = 0.5\n",
    "ANNEAL_RATE = 0.00003\n",
    "n_start = 512\n",
    "num_initial_bits = 512\n",
    "\n",
    "g = np.log(2)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Utilizzo Apple Silicon GPU (MPS)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Utilizzo NVIDIA GPU (CUDA)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Utilizzo la CPU\")\n",
    "\n",
    "# is_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(seed)\n",
    "if device.type == \"cuda\": # Mantieni la seed per CUDA se presente\n",
    "    torch.cuda.manual_seed(seed)\n",
    "elif device.type == \"mps\": # Imposta la seed anche per MPS se vuoi riproducibilità\n",
    "    torch.mps.manual_seed(seed)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if device.type == \"cuda\" or device.type == \"mps\" else {} # pin_memory può essere utile anche per MPS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9078dba",
   "metadata": {},
   "source": [
    "# Datas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e24ec7d",
   "metadata": {},
   "source": [
    "## HFM datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f3a3d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_HFM(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.data['examples'] = self.data['examples'].apply(lambda x: torch.tensor(np.fromstring(x.strip(\"[]\"), sep=' '), dtype=torch.float32))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        example = self.data.iloc[idx,1]\n",
    "        sample = {'example': example}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fda585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_HFM = Dataset_HFM(csv_file='data/feat_512_g_log2_numex_60000.csv',\n",
    "                          root_dir='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bda527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset_HFM,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07008e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_HFM_val = Dataset_HFM(csv_file='data/feat_512_g_log2_numex_10000.csv',\n",
    "                          root_dir='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8d75e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(\n",
    "    dataset_HFM,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3072d",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b732f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        './data/MNIST',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor()\n",
    "        ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    **kwargs\n",
    "    )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        './data/MNIST',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.ToTensor()\n",
    "        ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    **kwargs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629a76ae",
   "metadata": {},
   "source": [
    "## Gumbel softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf79c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_gumbel(shape, eps=1e-20):\n",
    "    # sample from a uniform distribution\n",
    "    U = torch.rand(shape)\n",
    "    '''if is_cuda:\n",
    "        U = U.cuda()'''\n",
    "    return -torch.log(-torch.log(U.to(device) + eps) + eps)\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature):\n",
    "    y = logits + sample_gumbel(logits.size())\n",
    "    return F.softmax(y / temperature, dim=-1)\n",
    "\n",
    "\n",
    "def gumbel_softmax(logits, temperature, hard=False):\n",
    "    y = gumbel_softmax_sample(logits, temperature)\n",
    "    \n",
    "    if not hard:\n",
    "        return y.view(-1, latent_dim * categorical_dim)\n",
    "    \n",
    "    shape = y.size()\n",
    "    _, ind = y.max(dim=-1)\n",
    "    y_hard = torch.zeros_like(y).view(-1, shape[-1])\n",
    "    y_hard.scatter_(1, ind.view(-1, 1), 1)\n",
    "    y_hard = y_hard.view(*shape)\n",
    "    # skip the gradient of y_hard\n",
    "    y_hard = (y_hard - y).detach() + y \n",
    "    return y_hard.view(-1, latent_dim * categorical_dim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17316138",
   "metadata": {},
   "source": [
    "### alternative gumbel softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762f08ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gumbel_softmax(logits, tau, hard=False):\n",
    "    U = torch.rand_like(logits)\n",
    "    G = -torch.log(-torch.log(U + 1e-20) + 1e-20)\n",
    "    y = F.softmax((logits + G) / tau, dim=-1)\n",
    "\n",
    "    if hard:\n",
    "        y_hard = torch.zeros_like(y)\n",
    "        y_hard.scatter_(-1, y.argmax(dim=-1, keepdim=True), 1.0)\n",
    "        y = (y_hard - y).detach() + y  # straight-through estimator\n",
    "\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c220620",
   "metadata": {},
   "source": [
    "# HFM distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "629a3a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_s_k(k, n, g): #0-indexed k\n",
    "    xi = 2 * np.exp(-g)\n",
    "    if abs(xi - 1) < 1e-6: #handles the case xi =1\n",
    "        E = (n - (k+1) + 2) / (2 * (n+1))\n",
    "    else:\n",
    "        E = 0.5 * (1 + (xi**(k) - 1) * (xi - 2) / (xi**n + xi -2))\n",
    "    return E\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f19ee0",
   "metadata": {},
   "source": [
    "# Class VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e51b88c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE_model, self).__init__()\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, latent_dim * categorical_dim)\n",
    "        self.fc4 = nn.Linear(latent_dim * categorical_dim, 128)\n",
    "        self.fc5 = nn.Linear(128, 256)\n",
    "        self.fc6 = nn.Linear(256, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def sample_img(self, img, temp, random=True):\n",
    "        with torch.no_grad():\n",
    "            logits_z = self.encode(img.view(-1, num_initial_bits))\n",
    "            logits_z = logits_z.view(-1, latent_dim, categorical_dim)\n",
    "            if random:\n",
    "                latent_z = gumbel_softmax(logits_z, temp, True)\n",
    "            else:\n",
    "                latent_z = logits_z.view(-1, latent_dim * categorical_dim)\n",
    "            logits_x = self.decode(latent_z)\n",
    "            dist_x = torch.distributions.Bernoulli(probs=logits_x)\n",
    "            sampled_img = dist_x.sample()\n",
    "        return sampled_img\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = self.relu(self.fc1(x))\n",
    "        h2 = self.relu(self.fc2(h1))\n",
    "        return self.relu(self.fc3(h2))\n",
    "\n",
    "    def decode(self, z):\n",
    "        h4 = self.relu(self.fc4(z))\n",
    "        h5 = self.relu(self.fc5(h4))\n",
    "        return self.sigmoid(self.fc6(h5))\n",
    "\n",
    "    def forward(self, data, temp, hard):\n",
    "        logits_z = self.encode(data.view(-1, num_initial_bits))\n",
    "        logits_z = logits_z.view(-1, latent_dim, categorical_dim)\n",
    "\n",
    "        probs_z = F.softmax(logits_z, dim=-1)\n",
    "        posterior_distrib = torch.distributions.Categorical(probs=probs_z)\n",
    "\n",
    "        prior_probs_list = []\n",
    "        for i in range(latent_dim):\n",
    "            prob_activation = mean_s_k(i, latent_dim, np.log(2))\n",
    "            prob_nonactivation = 1 - prob_activation\n",
    "            prior_probs_list.append([prob_activation, prob_nonactivation])\n",
    "\n",
    "        probs_prior_base = torch.tensor(prior_probs_list, device=device, dtype=torch.float32)\n",
    "        probs_prior = probs_prior_base.unsqueeze(0).expand(data.size(0), -1, -1)\n",
    "        prior_distrib = torch.distributions.Categorical(probs=probs_prior)\n",
    "\n",
    "\n",
    "        latent_z = gumbel_softmax(logits_z, temp)\n",
    "        latent_z = latent_z.view(-1, latent_dim * categorical_dim)\n",
    "\n",
    "        probs_x = self.decode(latent_z)\n",
    "        dist_x = torch.distributions.Bernoulli(probs=probs_x, validate_args=False)\n",
    "\n",
    "        rec_loss = dist_x.log_prob(data.view(-1, num_initial_bits)).sum(dim=-1)\n",
    "        logits_z_log = F.log_softmax(logits_z, dim=-1)\n",
    "\n",
    "        #KL è la somma su tutte le (singole KL calcolate sulla distr di prob di bernoulli di ogni feature), non ancora sommata su ogni esempio del batch \n",
    "        KL = (posterior_distrib.probs * (logits_z_log - prior_distrib.probs.log())).view(-1, latent_dim * categorical_dim).sum(dim=-1)\n",
    "        elbo = rec_loss - KL\n",
    "        # a questo punto si fa la media su tutti i valori del batch\n",
    "        loss = -elbo.mean()\n",
    "        return loss, KL.mean()\n",
    "    \n",
    "    def sample_from_prior(self, num_samples=1, temp_eval=0.01):\n",
    "        \"\"\"\n",
    "        Genera immagini campionando dallo spazio latente (prior).\n",
    "        num_samples: Quante immagini vuoi generare.\n",
    "        temp_eval: La temperatura da usare per la Gumbel-Softmax.\n",
    "                Un valore molto basso (~0.01) simula un campionamento one-hot.\n",
    "                Un valore di 1.0 rende il campionamento più \"soft\".\n",
    "        \"\"\"\n",
    "        self.eval() # Imposta il modello in modalità valutazione\n",
    "        with torch.no_grad(): # Non abbiamo bisogno di calcolare i gradienti qui\n",
    "\n",
    "            prior_probs_list = []\n",
    "            for i in range(latent_dim):\n",
    "                prob_cat0 = mean_s_k(i, latent_dim, np.log(2))\n",
    "                prob_cat1 = 1.0 - prob_cat0\n",
    "                prior_probs_list.append([prob_cat0, prob_cat1])\n",
    "\n",
    "            probs_prior_base = torch.tensor(prior_probs_list, device=device, dtype=torch.float32)\n",
    "\n",
    "            sampled_indices = torch.distributions.Categorical(probs=probs_prior_base).sample((num_samples,)).to(device)\n",
    "            # sampled_indices avrà forma (num_samples, latent_dim)\n",
    "\n",
    "            # Converti gli indici campionati in un formato one-hot (o soft)\n",
    "            # Per fare un sampling \"hard\" (one-hot), possiamo usare scatter_\n",
    "            # o direttamente creare i one-hot da sampled_indices\n",
    "            latent_z_one_hot = torch.zeros(num_samples, latent_dim, categorical_dim, device=device)\n",
    "            latent_z_one_hot.scatter_(-1, sampled_indices.unsqueeze(-1), 1)\n",
    "\n",
    "            latent_z_sampled = latent_z_one_hot.view(num_samples, latent_dim * categorical_dim)\n",
    "\n",
    "\n",
    "            probs_x = self.decode(latent_z_sampled)\n",
    "\n",
    "            dist_x = torch.distributions.Bernoulli(probs=probs_x)\n",
    "            generated_img = dist_x.sample()\n",
    "\n",
    "        self.train() # Riporta il modello in modalità addestramento\n",
    "        return generated_img # Ritorna le immagini generate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a67104",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8e35ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir='runs/discrete_VAE_HFM/_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb9549b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, epochs):\n",
    "    global_batch_idx = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        temp = temperature\n",
    "\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            global_batch_idx += 1\n",
    "            # Sposta i dati sul device corretto\n",
    "            data = data['example'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss, KL = model(data, temp, hard)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item() * len(data)\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % 100 == 1:\n",
    "                temp = np.maximum(temp * np.exp(-ANNEAL_RATE * batch_idx), temp_min)\n",
    "\n",
    "            '''\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader),\n",
    "                        loss.item()))\n",
    "                print(\"Temperature : \", temp)\n",
    "            '''\n",
    "\n",
    "            if global_batch_idx % log_interval_writer == 0:\n",
    "                writer.add_scalar('KL/Train', KL, global_step=global_batch_idx)\n",
    "\n",
    "\n",
    "        writer.add_scalar('Loss/Train', train_loss/len(train_loader.dataset), global_step=epoch)\n",
    "\n",
    "\n",
    "\n",
    "        '''\n",
    "        # Sposta l'immagine campionata sulla CPU per la visualizzazione con matplotlib\n",
    "        sampled = model.sample_img(data[0].view(-1, 28*28), temp).view(28, 28).detach().cpu()\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(6,4))\n",
    "        fig.suptitle('Reconstructed vs Real')\n",
    "        axs[0].imshow(sampled.reshape(28,28))\n",
    "        axs[0].axis('off')\n",
    "        axs[1].imshow(data[0].reshape(28,28).detach().cpu())\n",
    "        axs[1].axis('off')\n",
    "        plt.show()\n",
    "        '''\n",
    "\n",
    "        print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "            epoch, train_loss / len(train_loader.dataset)))\n",
    "        \n",
    "        # Validation\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss_sum = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in enumerate(val_loader):\n",
    "                data = data['example'].to(device)\n",
    "                loss, KL = model(data, temp, hard=True)\n",
    "                val_loss_sum += loss.item() * len(data)\n",
    "\n",
    "        writer.add_scalar('Loss/Validation', val_loss_sum/len(val_loader.dataset), global_step=epoch)\n",
    "\n",
    "        # Log histogram of weights and gradients\n",
    "        for name, param in model.named_parameters():\n",
    "            writer.add_histogram(f'Weights/{name}', param, global_step=epoch)\n",
    "            if param.grad is not None:\n",
    "                writer.add_histogram(f'Grads/{name}', param.grad, global_step=epoch)\n",
    "\n",
    "    writer.close()\n",
    "    print(\"Training completato e dati scritti su tensorboard\")\n",
    "\n",
    "\n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c53f6541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Apple Silicon (MPS). num_workers set to 0 to avoid pickling issues.\n",
      "====> Epoch: 0 Average loss: 259.6736\n",
      "====> Epoch: 1 Average loss: 257.1011\n",
      "====> Epoch: 2 Average loss: 256.9735\n",
      "====> Epoch: 3 Average loss: 256.8518\n",
      "====> Epoch: 4 Average loss: 256.6718\n",
      "====> Epoch: 5 Average loss: 256.4465\n",
      "====> Epoch: 6 Average loss: 256.2172\n",
      "====> Epoch: 7 Average loss: 256.0489\n",
      "====> Epoch: 8 Average loss: 255.8888\n",
      "====> Epoch: 9 Average loss: 255.7183\n",
      "====> Epoch: 10 Average loss: 255.5594\n",
      "====> Epoch: 11 Average loss: 255.4378\n",
      "====> Epoch: 12 Average loss: 255.3025\n",
      "====> Epoch: 13 Average loss: 255.2069\n",
      "====> Epoch: 14 Average loss: 255.1257\n",
      "====> Epoch: 15 Average loss: 255.0564\n",
      "====> Epoch: 16 Average loss: 254.9942\n",
      "====> Epoch: 17 Average loss: 254.9122\n",
      "====> Epoch: 18 Average loss: 254.8538\n",
      "====> Epoch: 19 Average loss: 254.8151\n",
      "Training completato e dati scritti su tensorboard\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Queste variabili sono definite globalmente, ma è buona pratica includerle qui\n",
    "    # per chiarezza se lo script è più grande.\n",
    "    # kwargs per DataLoader, MPS non supporta pin_memory con num_workers > 0\n",
    "    kwargs = {'num_workers': 0, 'pin_memory': True} if torch.backends.mps.is_available() else {}\n",
    "    # Per MPS, se `num_workers > 0` e `pin_memory=True`, PyTorch lancia un warning.\n",
    "    # È meglio impostare num_workers=0 per debug iniziale, poi aumentare se necessario.\n",
    "    # In questo caso, data la natura dell'errore, num_workers=0 è la prima cosa da provare.\n",
    "    if torch.backends.mps.is_available():\n",
    "        print(\"Running on Apple Silicon (MPS). num_workers set to 0 to avoid pickling issues.\")\n",
    "        kwargs = {'num_workers': 0, 'pin_memory': False} # pin_memory a False per MPS con num_workers=0\n",
    "\n",
    "\n",
    "    # Inizializzazione del dataset e dei DataLoader\n",
    "    dataset_HFM = Dataset_HFM(csv_file='data/feat_512_g_log2_numex_60000.csv',\n",
    "                            root_dir='data')\n",
    "    train_loader = DataLoader(\n",
    "        dataset_HFM,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        **kwargs\n",
    "    )\n",
    "    dataset_HFM_val = Dataset_HFM(csv_file='data/feat_512_g_log2_numex_10000.csv',\n",
    "                                root_dir='data')\n",
    "    val_loader = DataLoader(\n",
    "        dataset_HFM_val, # Importante: usa dataset_HFM_val qui, non dataset_HFM\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    my_model = VAE_model()\n",
    "    my_model.to(device)\n",
    "    optimizer = optim.Adam(my_model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Chiamata alla funzione train\n",
    "    train(my_model, optimizer, epochs=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4687879",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfefa73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_generated_images = 5\n",
    "generated_images = my_model.sample_from_prior(num_samples=num_generated_images)\n",
    "\n",
    "# Visualizza le immagini generate\n",
    "plt.figure(figsize=(num_generated_images * 2, 2))\n",
    "plt.suptitle(\"Immagini generate dal prior\", fontsize=16)\n",
    "for i in range(num_generated_images):\n",
    "    plt.subplot(1, num_generated_images, i + 1)\n",
    "    plt.imshow(generated_images[i].view(32, 16).detach().cpu().numpy(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f791d01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997030c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Python_nn)",
   "language": "python",
   "name": "python_nn_3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
